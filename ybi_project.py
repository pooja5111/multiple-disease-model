# -*- coding: utf-8 -*-
"""YBI project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xe1pt7vuZ-G4UUH3-q2z9x4nAm7_VroU
"""

# import library
import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt
import seaborn as sns

# import data
disease = pd.read_csv('https://github.com/ybifoundation/Dataset/raw/main/MultipleDiseasePrediction.csv')

#view data
disease

#info of data
disease.head()

#summary statistic
disease.info()

# check for missing values
disease.describe()

# correlation
disease.corr()

# visualize pairplot
disease.nunique()

# column names
disease.columns

# define y
y = disease['prognosis']

# define X
X = disease.drop(['prognosis'] , axis =1 )

print(X)
print(y)

y.shape

X.shape

# split data
from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.7,random_state=2529)

# verify shape
X_train.shape,X_test.shape,y_train.shape,y_test.shape

!pip install matplotlib-venn

!apt-get -qq install -y libarchive-dev && pip install -U libarchive
import libarchive

!apt-get -qq install -y graphviz && pip install pydot
import pydot

!pip install cartopy
import cartopy

# select model
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()

# train model
model.fit(X_train,y_train)

#predict with model
y_pred=model.predict(X_test)

# model evaluation
y_pred

np.array(y_test)

# model accuracy 
from sklearn.metrics import accuracy_score
accuracy_score(y_test, y_pred)

#model confusion matrix 
from sklearn.metrics._plot.confusion_matrix import confusion_matrix
print(confusion_matrix(y_test, y_pred))

from sklearn.metrics import classification_report
print(classification_report(y_test,y_pred))

# making a predictive system 
input_data = [[1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]
## changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)
# reshape the array as we are predicting for one instance 
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)
# standardize the input data as above we haven't standardize the data 
prediction = model.predict(input_data)
print('person has') 
print(prediction)

# saving the trained model
import pickle

filename = 'trained_model.rfc'
pickle.dump(model, open(filename, 'wb')) # wb mean write binary

# loading the saved model
loaded_model = pickle.load(open('trained_model.rfc', 'rb'))

# making a predictive system 
input_data = [[1,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]]
## changing the input_data to numpy array
input_data_as_numpy_array = np.asarray(input_data)
# reshape the array as we are predicting for one instance 
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)
# standardize the input data as above we haven't standardize the data 
prediction = loaded_model.predict(input_data)
print('person has') 
print(prediction)